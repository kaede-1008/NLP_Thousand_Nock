{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "desserts\n"
    }
   ],
   "source": [
    "# 文字列の逆順\n",
    "text = 'stressed'\n",
    "print(text[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "パトカー\n"
    }
   ],
   "source": [
    "# 「パタトクカシーー」\n",
    "text = \"パタトクカシーー\"\n",
    "print(text[::2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "パタトクカシーー\n"
    }
   ],
   "source": [
    "# 「パトカー」＋「タクシー」＝「パタトクカシーー」\n",
    "text1 = \"パトカー\"\n",
    "text2 = \"タクシー\"\n",
    "\n",
    "print(\"\".join(i+j for i, j in zip(text1, text2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5, 8, 9, 7, 9]\n"
    }
   ],
   "source": [
    "# 円周率\n",
    "text = \"Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.\"\n",
    "\n",
    "ans = [len(i.strip(\".,\")) for i in text.split()]\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "{'H': 1, 'He': 2, 'Li': 3, 'Be': 4, 'B': 5, 'C': 6, 'N': 7, 'O': 8, 'F': 9, 'Ne': 10, 'Na': 11, 'Mi': 12, 'Al': 13, 'Si': 14, 'P': 15, 'S': 16, 'Cl': 17, 'Ar': 18, 'K': 19, 'Ca': 20}\n"
    }
   ],
   "source": [
    "# 元素記号\n",
    "text = \"Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.\"\n",
    "ans = {word[:2-(i in [1, 5, 6, 7, 8, 9, 15, 16, 19])]: i for i, word in enumerate(text.replace(\".\", \"\").split(), 1)}\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['I', ' ', 'a', 'm', ' ', 'a', 'n', ' ', 'N', 'L', 'P', 'e', 'r']\n[['I'], ['am'], ['an'], ['NLPer']]\n['I ', ' a', 'am', 'm ', ' a', 'an', 'n ', ' N', 'NL', 'LP', 'Pe', 'er']\n[['I', 'am'], ['am', 'an'], ['an', 'NLPer']]\n['I a', ' am', 'am ', 'm a', ' an', 'an ', 'n N', ' NL', 'NLP', 'LPe', 'Per']\n[['I', 'am', 'an'], ['am', 'an', 'NLPer']]\n"
    }
   ],
   "source": [
    "# n-gram\n",
    "def n_gram(target, n):\n",
    "    return [target[idx:idx + n] for idx in range(len(target) - n + 1)]\n",
    "\n",
    "\n",
    "text = 'I am an NLPer'\n",
    "for i in range(1, 4):\n",
    "    print(n_gram(text, i))\n",
    "    print(n_gram(text.split(' '), i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "和集合: {'is', 'se', 'ag', 'ap', 'ad', 'gr', 'ar', 'ra', 'di', 'pa', 'ph'}\n積集合: {'ar', 'ra', 'ap', 'pa'}\n差集合: {'se', 'di', 'is', 'ad'}\nFalse\n"
    }
   ],
   "source": [
    "# 集合\n",
    "\n",
    "X_text = 'paraparaparadise'\n",
    "Y_text = 'paragraph'\n",
    "X = n_gram(X_text, 2)\n",
    "Y = n_gram(Y_text, 2)\n",
    "\n",
    "print(f'和集合: {set(X) | set(Y)}')\n",
    "print(f'積集合: {set(X) & set(Y)}')\n",
    "print(f'差集合: {set(X) - set(Y)}')\n",
    "print('se' in (set(X) & set(Y)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "12時の気温は22.4\n"
    }
   ],
   "source": [
    "# テンプレートによる文生成\n",
    "\n",
    "def gen_text(x, y, z):\n",
    "    return f'{x}時の{y}は{z}'\n",
    "\n",
    "x = 12\n",
    "y = '気温'\n",
    "z = 22.4\n",
    "print(gen_text(x, y, z))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "gsrh rh z nvhhztv.\nthis is a message.\n"
    }
   ],
   "source": [
    "# 暗号文\n",
    "\n",
    "def cipher(text):\n",
    "    text = [chr(219 - ord(w)) if 97 <= ord(w) <= 122 else w for w in text]\n",
    "    return ''.join(text)\n",
    "\n",
    "\n",
    "text = 'this is a message.'\n",
    "ans = cipher(text)\n",
    "print(ans)\n",
    "ans = cipher(ans)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['I', 'c’dnolut', 'bieelve', 'that', 'I', 'cloud', 'atullcay', 'unedrtsnad', 'what', 'I', 'was', 'riednag', ':', 'the', 'phaoenenml', 'power', 'of', 'the', 'hmuan', 'mind', '.']\n"
    }
   ],
   "source": [
    "# Typoglycemia\n",
    "\n",
    "import random\n",
    "\n",
    "\n",
    "def shuffleWord(word):\n",
    "    if len(word) <= 4:\n",
    "        return word\n",
    "    else:\n",
    "        start = word[0]\n",
    "        end = word[-1]\n",
    "        others = random.sample(list(word[1:-1]), len(word[1:-1]))\n",
    "        return ''.join([start] + others + [end])\n",
    "\n",
    "\n",
    "text = 'I couldn’t believe that I could actually understand what I was reading : the phenomenal power of the human mind .'\n",
    "ans = [shuffleWord(w) for w in text.split()]\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2780\n"
    }
   ],
   "source": [
    "# 行数のカウント\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./popular-names.txt', sep='\\t', header=None)\n",
    "\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# タブをスペースに変換\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./popular-names.txt', sep='\\t', header=None)\n",
    "df.to_csv('ans11.txt', sep=' ', index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1列目をcol1.txtに2列目をcol2.txtに保存\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./popular-names.txt', sep='\\t', header=None)\n",
    "df[0].to_csv('col1.txt', index=False, header=None)\n",
    "df[1].to_csv('col2.txt', index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# col1.txtとcol2.txtをマージ\n",
    "import pandas as pd\n",
    "\n",
    "c1 = pd.read_csv('col1.txt', header=None)\n",
    "c2 = pd.read_csv('col2.txt', header=None)\n",
    "\n",
    "df = pd.concat([c1, c2], axis=1)\n",
    "df.to_csv('ans13.txt', sep='\\t', index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "-f\n              0  1      2     3\n0          Mary  F   7065  1880\n1          Anna  F   2604  1880\n2          Emma  F   2003  1880\n3     Elizabeth  F   1939  1880\n4        Minnie  F   1746  1880\n5      Margaret  F   1578  1880\n6           Ida  F   1472  1880\n7         Alice  F   1414  1880\n8        Bertha  F   1320  1880\n9         Sarah  F   1288  1880\n10         John  M   9655  1880\n11      William  M   9532  1880\n12        James  M   5927  1880\n13      Charles  M   5348  1880\n14       George  M   5126  1880\n15        Frank  M   3242  1880\n16       Joseph  M   2632  1880\n17       Thomas  M   2534  1880\n18        Henry  M   2444  1880\n19       Robert  M   2415  1880\n20         Mary  F   6919  1881\n21         Anna  F   2698  1881\n22         Emma  F   2034  1881\n23    Elizabeth  F   1852  1881\n24     Margaret  F   1658  1881\n25       Minnie  F   1653  1881\n26          Ida  F   1439  1881\n27        Annie  F   1326  1881\n28       Bertha  F   1324  1881\n29        Alice  F   1308  1881\n...         ... ..    ...   ...\n2750       Liam  M  18798  2017\n2751       Noah  M  18410  2017\n2752    William  M  14967  2017\n2753      James  M  14291  2017\n2754      Logan  M  14014  2017\n2755   Benjamin  M  13797  2017\n2756      Mason  M  13549  2017\n2757     Elijah  M  13344  2017\n2758     Oliver  M  13193  2017\n2759      Jacob  M  13178  2017\n2760       Emma  F  18688  2018\n2761     Olivia  F  17921  2018\n2762        Ava  F  14924  2018\n2763   Isabella  F  14464  2018\n2764     Sophia  F  13928  2018\n2765  Charlotte  F  12940  2018\n2766        Mia  F  12642  2018\n2767     Amelia  F  12301  2018\n2768     Harper  F  10582  2018\n2769     Evelyn  F  10376  2018\n2770       Liam  M  19837  2018\n2771       Noah  M  18267  2018\n2772    William  M  14516  2018\n2773      James  M  13525  2018\n2774     Oliver  M  13389  2018\n2775   Benjamin  M  13381  2018\n2776     Elijah  M  12886  2018\n2777      Lucas  M  12585  2018\n2778      Mason  M  12435  2018\n2779      Logan  M  12352  2018\n\n[2780 rows x 4 columns]\n"
    }
   ],
   "source": [
    "# 先頭からN行を出力\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "if len(sys.argv) == 1:\n",
    "    print('引数がすくない')\n",
    "else:\n",
    "    n = int(sys.argv[1])\n",
    "    df = pd.read_csv('./popular-names.txt', sep='\\t', header=None)\n",
    "    print(df.head(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '-f'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-a48e76bf56e3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Set arg n, like \"python ans15.py 5\"'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./popular-names.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'/t'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: '-f'"
     ]
    }
   ],
   "source": [
    "# 末尾のN行を出力\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "if len(sys.argv) == 1:\n",
    "    print('引数が少ない')\n",
    "else:\n",
    "    n = int(sys.argv[1])\n",
    "    df = pd.read_csv('./popular-names.txt', sep='/t', header=None)\n",
    "    print(df.tail(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 16\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "if len(sys.argv) == 1:\n",
    "    print('引数が少ない')\n",
    "else:\n",
    "    n = int(sys.argv[1])\n",
    "    df = pd.read_csv('./popular-names.txt', sep='\\t', header=None)\n",
    "    nrow = -(-len(df)//n)\n",
    "\n",
    "    for i in range(n):\n",
    "        df.loc[nrow * i:row * (i + 1)].to_csv(f'ans16_{i}', sep='\\t', index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['Mary' 'Anna' 'Emma' 'Elizabeth' 'Minnie' 'Margaret' 'Ida' 'Alice'\n 'Bertha' 'Sarah' 'John' 'William' 'James' 'Charles' 'George' 'Frank'\n 'Joseph' 'Thomas' 'Henry' 'Robert' 'Annie' 'Edward' 'Clara' 'Florence'\n 'Ethel' 'Bessie' 'Harry' 'Helen' 'Ruth' 'Marie' 'Lillian' 'Mildred'\n 'Dorothy' 'Frances' 'Walter' 'Evelyn' 'Virginia' 'Richard' 'Betty'\n 'Donald' 'Doris' 'Shirley' 'Barbara' 'Patricia' 'Joan' 'Nancy' 'Carol'\n 'David' 'Ronald' 'Judith' 'Linda' 'Sandra' 'Carolyn' 'Sharon' 'Michael'\n 'Susan' 'Donna' 'Larry' 'Kathleen' 'Deborah' 'Gary' 'Karen' 'Debra'\n 'Pamela' 'Cynthia' 'Mark' 'Steven' 'Lisa' 'Jeffrey' 'Lori' 'Kimberly'\n 'Tammy' 'Angela' 'Michelle' 'Jennifer' 'Melissa' 'Christopher' 'Brian'\n 'Amy' 'Laura' 'Tracy' 'Julie' 'Jason' 'Scott' 'Stephanie' 'Heather'\n 'Nicole' 'Matthew' 'Rebecca' 'Jessica' 'Amanda' 'Daniel' 'Kelly' 'Joshua'\n 'Crystal' 'Ashley' 'Megan' 'Brittany' 'Andrew' 'Justin' 'Samantha'\n 'Lauren' 'Emily' 'Brandon' 'Tyler' 'Taylor' 'Nicholas' 'Jacob' 'Hannah'\n 'Austin' 'Alexis' 'Rachel' 'Madison' 'Abigail' 'Olivia' 'Ethan' 'Anthony'\n 'Isabella' 'Ava' 'Sophia' 'Chloe' 'Alexander' 'Mia' 'Jayden' 'Noah'\n 'Aiden' 'Mason' 'Liam' 'Charlotte' 'Harper' 'Benjamin' 'Elijah' 'Amelia'\n 'Logan' 'Oliver' 'Lucas']\n"
    }
   ],
   "source": [
    "# 1列目の文字列の異なり\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv('./popular-names.txt', sep='\\t', header=None)\n",
    "print(df[0].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0  1      2     3\n1340      Linda  F  99689  1947\n1360      Linda  F  96211  1948\n1350      James  M  94757  1947\n1550    Michael  M  92704  1957\n1351     Robert  M  91640  1947\n1380      Linda  F  91016  1949\n1530    Michael  M  90656  1956\n1570    Michael  M  90517  1958\n1370      James  M  88584  1948\n1490    Michael  M  88528  1954\n1510    Michael  M  88327  1955\n1352       John  M  88319  1947\n1330      James  M  87436  1946\n1430      James  M  87261  1951\n1450      James  M  87063  1952\n1630    Michael  M  86917  1961\n1390      James  M  86857  1949\n1451     Robert  M  86604  1952\n1431     Robert  M  86351  1951\n1491     Robert  M  86298  1954\n1492      James  M  86272  1954\n1470     Robert  M  86256  1953\n1511      David  M  86253  1955\n1410      James  M  86224  1950\n1471      James  M  86099  1953\n1610      David  M  85929  1960\n1371     Robert  M  85475  1948\n1810    Michael  M  85302  1970\n1590    Michael  M  85251  1959\n1790    Michael  M  85203  1969\n...         ... ..    ...   ...\n129    Florence  F   1860  1886\n107      Bertha  F   1860  1885\n108         Ida  F   1854  1885\n87        Clara  F   1852  1884\n23    Elizabeth  F   1852  1881\n399       Henry  M   1831  1899\n45     Margaret  F   1821  1882\n88       Bertha  F   1789  1884\n4        Minnie  F   1746  1880\n89        Annie  F   1739  1884\n109       Annie  F   1703  1885\n66       Bertha  F   1681  1883\n46          Ida  F   1673  1882\n24     Margaret  F   1658  1881\n25       Minnie  F   1653  1881\n67          Ida  F   1634  1883\n68        Annie  F   1589  1883\n5      Margaret  F   1578  1880\n69        Clara  F   1548  1883\n47        Alice  F   1542  1882\n48       Bertha  F   1508  1882\n49        Annie  F   1492  1882\n6           Ida  F   1472  1880\n26          Ida  F   1439  1881\n7         Alice  F   1414  1880\n27        Annie  F   1326  1881\n28       Bertha  F   1324  1881\n8        Bertha  F   1320  1880\n29        Alice  F   1308  1881\n9         Sarah  F   1288  1880\n\n[2780 rows x 4 columns]\n"
    }
   ],
   "source": [
    "# 各行を3コラム目の数値の降順にソート\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./popular-names.txt', sep='\\t', header=None)\n",
    "print(df.sort_values(2, ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "James          118\nWilliam        111\nRobert         108\nJohn           108\nMary            92\nCharles         75\nMichael         74\nElizabeth       73\nJoseph          70\nMargaret        60\nGeorge          58\nThomas          58\nDavid           57\nRichard         51\nHelen           45\nFrank           43\nChristopher     43\nAnna            41\nEdward          40\nRuth            39\nPatricia        38\nMatthew         37\nDorothy         36\nEmma            35\nBarbara         32\nDaniel          31\nJoshua          31\nJennifer        26\nLinda           26\nEmily           26\n              ... \nKathleen         4\nJustin           4\nBenjamin         4\nChloe            4\nAustin           4\nLillian          4\nHarper           3\nAiden            3\nMegan            3\nElijah           3\nEvelyn           3\nLarry            2\nLauren           2\nOliver           2\nRebecca          2\nAmelia           2\nBessie           2\nLogan            2\nJulie            1\nScott            1\nWalter           1\nCarolyn          1\nLucas            1\nLaura            1\nRachel           1\nCrystal          1\nLori             1\nPamela           1\nTracy            1\nKelly            1\nName: 0, Length: 136, dtype: int64\n"
    }
   ],
   "source": [
    "# 各行の1コラム目の文字列の出現頻度を求め，出現頻度の高い順に並べる\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv('./popular-names.txt', sep='\\t', header=None)\n",
    "print(df[0].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "UnicodeDecodeError",
     "evalue": "'cp932' codec can't decode byte 0x85 in position 87: illegal multibyte sequence",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-fa4ee06c2295>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'./jawiki-country.json.gz'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mukText\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'title==\"イギリス\"'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mukText\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\pandas\\io\\json\\json.py\u001b[0m in \u001b[0;36mread_json\u001b[1;34m(path_or_buf, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, lines, chunksize, compression)\u001b[0m\n\u001b[0;32m    358\u001b[0m         \u001b[0mkeep_default_dates\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeep_default_dates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m         \u001b[0mprecise_float\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprecise_float\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdate_unit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdate_unit\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 360\u001b[1;33m         \u001b[0mlines\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlines\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompression\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompression\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    361\u001b[0m     )\n\u001b[0;32m    362\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\pandas\\io\\json\\json.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, filepath_or_buffer, orient, typ, dtype, convert_axes, convert_dates, keep_default_dates, numpy, precise_float, date_unit, encoding, lines, chunksize, compression)\u001b[0m\n\u001b[0;32m    402\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_data_from_filepath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 404\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_preprocess_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    405\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_preprocess_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\pandas\\io\\json\\json.py\u001b[0m in \u001b[0;36m_preprocess_data\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    413\u001b[0m         \"\"\"\n\u001b[0;32m    414\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'read'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 415\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    416\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'read'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    417\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'cp932' codec can't decode byte 0x85 in position 87: illegal multibyte sequence"
     ]
    }
   ],
   "source": [
    "# JSONデータの読み込み\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json('./jawiki-country.json.gz', lines=True)\n",
    "ukText = df.query('title==\"イギリス\"')['text'].values[0]\n",
    "print(ukText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "06459f97-dc20-4bca-b67d-a43c58ee31b1",
   "display_name": "'Python Interactive'"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}